---
layout: post
title:  Marketing Ploys
categories: [Science, Research Integrity]
excerpt: This is a bit like a weather report for the Netherlands only mentioning temperatures in Charleston. Sure, it is nice to know if Charlestonian are cosy, but it doesn’t tell me if I should wear Moon Boots or sandals tomorrow.
---

Would cutting the meter in half double your height? Would stretching the second make you faster than Usain Bolt? If you ask marketing people, the answer is yes. 

The example I am most familiar with comes from mass spectrometry. In many mass spectrometers, performance metrics decrease with the mass, or mass-to-charge ratio, of the ions analyzed. When I got started in the field, vendors reported metrics and specifications at mass 800 - right in the middle of the range measured. This seemed sensible - and was neither the best or the worst case, but somewhere in between. At some point, some clever person in a marketing department somewhere must have figured out that changing the measuring stick - the mass-to-charge at which the metric is given, gives the appearance of improvement, whether or not there was any actual increase in performance. Consequently, the performance metrics started to be reported at 600, then at 400, which incidentally is close to the maximum performance at the bottom end of typical measurements. But why let reality stop a successful marketing ploy? 

Consequently, the same performance metrics are now given at mass 200 - outside what is typically measured. {% include pullquote.html quote="This is a bit like a weather report for the Netherlands only mentioning temperatures in Charleston. Sure, it is nice to know if Charlestonian are cosy, but it doesn’t tell me if I should wear [Moon Boots](https://en.wikipedia.org/wiki/Moon_Boot) or sandals tomorrow." %} 

This has real consequences for our ability to understand how published mass spectrometry data was acquired and how to correctly interpret it. Sure, most papers give a number on the performance metric - but how do we know what the numbers mean when we do not know which yardstick was used? Given the importance of well-defined units and reporting standards in science, the success of such marketing ploys are an embarrassment to the field.
&nbsp;  
&nbsp;  
&nbsp;  
